{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hola &#x1F600;,\n",
    "\n",
    "Soy **Hesus Garcia** ‚Äì **\"Soy el √∫nico Hesus que conoces (y probablemente conocer√°s) üåü\"** ‚Äì S√≠, como \"Jes√∫s\", pero con una H que me hace √∫nico. Puede sonar raro, pero cr√©eme, ¬°no lo olvidar√°s! Como tu revisor en Triple-Ten, estoy aqu√≠ para guiarte y ayudarte a mejorar tu c√≥digo. Si algo necesita un ajuste, no hay de qu√© preocuparse; ¬°aqu√≠ estoy para hacer que tu trabajo brille con todo su potencial! ‚ú®\n",
    "\n",
    "Cada vez que encuentre un detalle importante en tu c√≥digo, te lo se√±alar√© para que puedas corregirlo y as√≠ te prepares para un ambiente de trabajo real, donde el l√≠der de tu equipo actuar√≠a de manera similar. Si en alg√∫n momento no logras solucionar el problema, te dar√© m√°s detalles para ayudarte en nuestra pr√≥xima oportunidad de revisi√≥n.\n",
    "\n",
    "Es importante que cuando encuentres un comentario, **no los muevas, no los modifiques, ni los borres**.\n",
    "\n",
    "---\n",
    "\n",
    "### Formato de Comentarios\n",
    "\n",
    "Revisar√© cuidadosamente cada implementaci√≥n en tu notebook para asegurar que cumpla con los requisitos y te dar√© comentarios de acuerdo al siguiente formato:\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br>\n",
    "    \n",
    "<b>√âxito</b> - ¬°Excelente trabajo! Esta parte est√° bien implementada y contribuye significativamente al an√°lisis de datos o al proyecto. Contin√∫a aplicando estas buenas pr√°cticas en futuras secciones.\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br>\n",
    "    \n",
    "<b>Atenci√≥n</b> ‚ö†Ô∏è - Este c√≥digo est√° correcto, pero se puede optimizar. Considera implementar mejoras para que sea m√°s eficiente y f√°cil de leer. Esto fortalecer√° la calidad de tu proyecto.\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br>\n",
    "    \n",
    "<b>A resolver</b> ‚ùó - Aqu√≠ hay un problema o error en el c√≥digo que es necesario corregir para aprobar esta secci√≥n. Por favor, revisa y corrige este punto, ya que es fundamental para la validez del an√°lisis y la precisi√≥n de los resultados.\n",
    "    \n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "Al final de cada revisi√≥n, recibir√°s un **Comentario General del Revisor** que incluir√°:\n",
    "\n",
    "- **Aspectos positivos:** Un resumen de los puntos fuertes de tu proyecto.\n",
    "- **√Åreas de mejora:** Sugerencias sobre aspectos donde puedes mejorar.\n",
    "- **Temas adicionales para investigar:** Ideas de temas opcionales que puedes explorar por tu cuenta para desarrollar a√∫n m√°s tus habilidades.\n",
    "\n",
    "Estos temas adicionales no son obligatorios en esta etapa, pero pueden serte √∫tiles para profundizar en el futuro.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Esta estructura en vi√±etas facilita la lectura y comprensi√≥n de cada parte del comentario final.\n",
    "\n",
    "Tambi√©n puedes responderme de la siguiente manera si tienes alguna duda o quieres aclarar algo espec√≠fico:\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta del estudiante</b> <a class=\"tocSkip\"></a>\n",
    "    \n",
    "Aqu√≠ puedes escribir tu respuesta o pregunta sobre el comentario.\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "**¬°Empecemos!** &#x1F680;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Predictivo para Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El presente trabajo tiene como objetivo evaluar y comparar distintos modelos de clasificaci√≥n para resolver un problema de detecci√≥n binaria de clientes propensos a realizar cancelaciones. Para ello, se implementaron y analizaron modelos de Regresi√≥n Log√≠stica, √Årboles de Decisi√≥n y Bosques Aleatorios.\n",
    "Dado que se trata de un conjunto de datos desbalanceado, se aplicaron t√©cnicas de ajuste de equilibrio como la asignaci√≥n de pesos a las clases, sobremuestreo (upsampling) y submuestreo (downsampling), con el fin de mejorar el desempe√±o de los modelos en la clase minoritaria.\n",
    "\n",
    "El rendimiento de cada modelo se midi√≥ a trav√©s de la m√©trica F1, considerando un valor m√≠nimo de 0.59 como criterio de aceptaci√≥n. Asimismo, para el mejor modelo se calcul√≥ el valor de AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploracion inicial de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el archivo CSV y lo almacenamos como un DataFrame llamado data.\n",
    "data = pd.read_csv('data\\Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripci√≥n de los datos.**\n",
    "\n",
    "- RowNumber: √≠ndice de cadena de datos\n",
    "- CustomerId: identificador de cliente √∫nico\n",
    "- Surname: apellido\n",
    "- CreditScore: valor de cr√©dito\n",
    "- Geography: pa√≠s de residencia\n",
    "- Gender: sexo\n",
    "- Age: edad\n",
    "- Tenure: per√≠odo durante el cual ha madurado el dep√≥sito a plazo fijo de un cliente (a√±os)\n",
    "- Balance: saldo de la cuenta\n",
    "- NumOfProducts: n√∫mero de productos bancarios utilizados por el cliente\n",
    "- HasCrCard: el cliente tiene una tarjeta de cr√©dito (1 - s√≠; 0 - no)\n",
    "- IsActiveMember: actividad del cliente (1 - s√≠; 0 - no)\n",
    "- EstimatedSalary: salario estimado\n",
    "\n",
    "\n",
    "**Objetivo:**\n",
    "- Exited: El cliente se ha ido (1 - s√≠; 0 - no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n"
     ]
    }
   ],
   "source": [
    "# Mostramos las primeras 5 filas.\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostramos info para 'data'\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "- `data` tiene 10000 filas y 14 columnas.\n",
    "- Los tipos de datos son correctos para cada columna.\n",
    "- Vemos que tenemos NaN en la columna 'Tenure'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Mostramos describe en 'data'\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "- **Exited:** muestra un promedio de 0.203 lo que representa que el 20.3% de los clientes se ha retirado del banco.\n",
    "- **Tenure:**\tTiene 9091 no nulos. Debemos observar con detalle.\n",
    "- **Balance:**\t25% de los clientes tienen saldo 0.\n",
    "- **NumOfProducts:**\tCasi todos tienen 1 o 2 productos.\n",
    "- **IsActiveMember:**\tUn promdeio de 51.5% de clientes activos \n",
    "- **CreditScore:**\tPromedio en 650, con m√≠nimo de 350.\n",
    "- **Age:**\tAmplio rango, desde los 18 hasta 92 a√±os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de filas duplicadas en data 0\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos el numero de duplicados en 'data'.\n",
    "print(\"N√∫mero de filas duplicadas en data\", data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de NaN en users_behavior RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contamos NaN en 'data'.\n",
    "print(\"N√∫mero de NaN en users_behavior\", data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias por compartir esta primera parte del proyecto. Aqu√≠ tienes el comentario correspondiente:\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br>\n",
    "\n",
    "<b>√âxito</b> - Muy buen comienzo. La introducci√≥n est√° bien contextualizada y la descripci√≥n de los datos es clara y detallada. Has identificado correctamente las variables relevantes, la presencia de valores faltantes en `Tenure` y la distribuci√≥n de clases en `Exited`, lo cual es clave para preparar un modelo predictivo eficaz. Adem√°s, la exploraci√≥n inicial es completa y ordenada. ¬°Excelente trabajo!\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de NaN en `Tenure`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que los valores ausentes corresponde al 9% los reemplazaremos con la mediana de la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de NaN en users_behavior RowNumber          0\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n",
      "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.00000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800      4.99790   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806      2.76001   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000      0.00000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.00000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.00000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.00000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000     10.00000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Reemplazamos NaN con la mediana de 'Tenure'.\n",
    "data['Tenure'] = data['Tenure'].fillna(data['Tenure'].median())\n",
    "\n",
    "# Contamos el numero de NaN en 'data'\n",
    "print(\"N√∫mero de NaN en users_behavior\", data.isna().sum())\n",
    "\n",
    "# Mostramos describe en 'data'\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "- Para 'Tenure' ahora el numero de valores es 10000.\n",
    "- El promedio, Q2 y Q3 se mantienen igual.\n",
    "- Q1 aumenta de 2 a 3.\n",
    "- La desviacion estandar se disminuy√≥ 0,134713.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br>\n",
    "\n",
    "<b>√âxito</b> - Excelente manejo de valores nulos. Elegiste correctamente reemplazar con la mediana dado el bajo porcentaje de valores faltantes y la naturaleza discreta de la variable. Adem√°s, acompa√±aste el cambio con un an√°lisis descriptivo que demuestra una revisi√≥n cuidadosa del impacto del imputado. ¬°Buen trabajo documentando el efecto en los cuantiles y la desviaci√≥n est√°ndar!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo del modelo predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Transformacion de caracter√≠sticas categ√≥ricas en num√©ricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas 'Geography' y 'Gender' no muestran categorias que necesiten numeracion ordinal, el nombre de los paises o el sexo de los clientes es indiferente sea cual sea el numero que se les otorgue. Es por esto que los datos de estas columnas son *variables nominales.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore  Age  Tenure    Balance  \\\n",
      "0          1    15634602  Hargrave          619   42     2.0       0.00   \n",
      "1          2    15647311      Hill          608   41     1.0   83807.86   \n",
      "2          3    15619304      Onio          502   42     8.0  159660.80   \n",
      "\n",
      "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
      "0              1          1               1        101348.88       1   \n",
      "1              1          0               1        112542.58       0   \n",
      "2              3          1               0        113931.57       1   \n",
      "\n",
      "   Geography_Germany  Geography_Spain  Gender_Male  \n",
      "0                  0                0            0  \n",
      "1                  0                1            0  \n",
      "2                  0                0            0  \n",
      "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.00000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800      4.99790   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806      2.76001   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000      0.00000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.00000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.00000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.00000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000     10.00000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  Geography_Germany  Geography_Spain  \\\n",
      "count     10000.000000  10000.000000       10000.000000     10000.000000   \n",
      "mean     100090.239881      0.203700           0.250900         0.247700   \n",
      "std       57510.492818      0.402769           0.433553         0.431698   \n",
      "min          11.580000      0.000000           0.000000         0.000000   \n",
      "25%       51002.110000      0.000000           0.000000         0.000000   \n",
      "50%      100193.915000      0.000000           0.000000         0.000000   \n",
      "75%      149388.247500      0.000000           1.000000         0.000000   \n",
      "max      199992.480000      1.000000           1.000000         1.000000   \n",
      "\n",
      "        Gender_Male  \n",
      "count  10000.000000  \n",
      "mean       0.545700  \n",
      "std        0.497932  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Transformamos  caracter√≠sticas categ√≥ricas en num√©ricas\n",
    "data_ohe = pd.get_dummies(data[['Geography', 'Gender']], drop_first = True)\n",
    "\n",
    "# Unimos data con data_ohe elimimando las columnas 'Geography', 'Gender' de data\n",
    "data_final = pd.concat([data.drop(['Geography', 'Gender'], axis=1), data_ohe], axis=1)\n",
    "\n",
    "# Mostramos data_final\n",
    "print(data_final.head(3))\n",
    "\n",
    "# Usamos describe en 'data_final'\n",
    "print(data_final.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "- El 54.45% de los clientes son hombres.\n",
    "- Se distribuyen geograficamente en 25.09% en Germany, 24.77% en Spain y 50.14% en France."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br>\n",
    "\n",
    "<b>√âxito</b> - ¬°Muy bien aplicado el one-hot encoding! Has identificado correctamente que las variables 'Geography' y 'Gender' son categ√≥ricas nominales, y realizaste la transformaci√≥n de forma adecuada usando pd.get_dummies() con drop_first=True para evitar la multicolinealidad. Adem√°s, tu an√°lisis posterior de distribuci√≥n por g√©nero y pa√≠s en las nuevas variables demuestra un entendimiento s√≥lido del proceso de transformaci√≥n. ¬°Sigue as√≠!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Definicion de features y target para cada categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las variables para features y target\n",
    "# Eliminamos las columnas que no aportan valor en features.\n",
    "features = data_final.drop(['RowNumber','CustomerId','Surname','Exited'], axis=1)\n",
    "target = data_final['Exited']\n",
    "\n",
    "# Dividimos en variables para entrenamiento y validacion\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features,\n",
    "                                                                              target,\n",
    "                                                                              test_size = 0.25,\n",
    "                                                                              random_state = 12345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br>\n",
    "\n",
    "<b>√âxito</b> - Excelente definici√≥n de las variables features y target. Has identificado correctamente columnas que no aportan valor predictivo (RowNumber, CustomerId, Surname) y las has excluido de features. Adem√°s, la divisi√≥n entre conjunto de entrenamiento y validaci√≥n est√° bien ejecutada con train_test_split, incluyendo la semilla random_state para asegurar reproducibilidad. ¬°Buen trabajo organizando tu flujo de trabajo!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Entrenamiento de modelos sin Equilibrar las Clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Regresion logistica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-Score: 0.45\n",
      "Recall-Score: 0.06728971962616823\n",
      "F1-Score: 0.11707317073170732\n"
     ]
    }
   ],
   "source": [
    "# Definimos el modelo con LogisticRegression\n",
    "model_1 = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "\n",
    "# Entrenamos al modelo con features_train y target_train\n",
    "model_1.fit(features_train, target_train)\n",
    "\n",
    "# Definimos una variable para las predicciones del modelo\n",
    "predicted_valid_1 = model_1.predict(features_valid)\n",
    "\n",
    "# Calculamos  Precision\n",
    "print(\"Precision-Score:\", precision_score(target_valid, predicted_valid_1))\n",
    "\n",
    "# Calculamos  Recall\n",
    "print(\"Recall-Score:\", recall_score(target_valid, predicted_valid_1))\n",
    "\n",
    "# Calculamos  F1\n",
    "print(\"F1-Score:\", f1_score(target_valid, predicted_valid_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "- Precision nos muestra que de todos los clientes que el modelo predijo que se ir√≠an, solo el 45% realmente se fueron.\n",
    "- Recall nos muestra que de todos los clientes que realmente se fueron, el modelo solo detect√≥ el 6.72%.\n",
    "- El valor de F1 muestra un bajo desempe√±o del modelo. No se acerca al valor objetivo de 0.59. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. √Årbol de Decisi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ning√∫n valor en el rango super√≥ el valor m√≠nimo en F1 (0.59)\n"
     ]
    }
   ],
   "source": [
    "# Creamos un ciclo for para determinar el valor para max_depth donde f1_score sea mayor.\n",
    "best_f1 = 0\n",
    "best_depth = None\n",
    "\n",
    "for depth in range(1, 30):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_depth = depth\n",
    "\n",
    "# Mostrar el mejor si supera 0.59\n",
    "if best_f1 >= 0.59:\n",
    "    print(f'Mejor max_depth: {best_depth}, F1-Score: {best_f1:.3f}')\n",
    "else:\n",
    "    print('Ning√∫n valor en el rango super√≥ el valor m√≠nimo en F1 (0.59)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque ningun valor en max_depth nos permitir√° igualar o superar la metrica para f1. Realizaremos la prueba con el modelo y veremos sus otras metricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor max_depth: 5 con F1: 0.5697940503432494\n"
     ]
    }
   ],
   "source": [
    "# Buscamos el mejor valor para max_depth\n",
    "best_f1 = 0\n",
    "best_depth = 0\n",
    "\n",
    "for depth in range(1, 10):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predictions_valid)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_depth = depth\n",
    "\n",
    "print(f'Mejor max_depth: {best_depth} con F1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7345132743362832\n",
      "Recall: 0.4654205607476635\n",
      "F1: 0.5697940503432494\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo teniendo en cuenta los hiperparametros.\n",
    "model_2 = DecisionTreeClassifier(random_state=12345, max_depth=5)\n",
    "model_2.fit(features_train, target_train)\n",
    "predicted_valid_2 = model_2.predict(features_valid)\n",
    "\n",
    "print('Precision:', precision_score(target_valid, predicted_valid_2))\n",
    "print('Recall:', recall_score(target_valid, predicted_valid_2))\n",
    "print('F1:', f1_score(target_valid, predicted_valid_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones.**\n",
    "\n",
    "- Precision nos muestra que de todos los clientes que el modelo predijo que se ir√≠an, el 73% realmente se fueron.\n",
    "- Recall nos muestra que de todos los clientes que realmente se fueron, el modelo  detect√≥ el 46.54%.\n",
    "- El valor de F1 muestra un desempe√±o de 0.569, un valor cercano al umbral deseado de 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Bosque Aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de validaci√≥n (n_estimators = 9): 0.8436\n"
     ]
    }
   ],
   "source": [
    "# Creamos un ciclo for para determinar el mejor valor para n_estimators\n",
    "\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 11):\n",
    "    model = RandomForestClassifier(random_state=54321, n_estimators=est)\n",
    "    model.fit(features_train,target_train)\n",
    "    score = model.score(features_valid,target_valid)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print(\"La exactitud del mejor modelo en el conjunto de validaci√≥n (n_estimators = {}): {}\".format(best_est, best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-Score: 0.6978021978021978\n",
      "Recall-Score: 0.4747663551401869\n",
      "F1-Score: 0.5650723025583982\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo de Bosque Aleatorio teniendo en cuenta los hiperparametros.\n",
    "model_3 = RandomForestClassifier(random_state=54321, n_estimators=9)\n",
    "model_3.fit(features_train, target_train)\n",
    "predicted_valid_3 = model_3.predict(features_valid)\n",
    "\n",
    "# Calculamos  Precision\n",
    "print(\"Precision-Score:\", precision_score(target_valid, predicted_valid_3))\n",
    "\n",
    "# Calculamos  Recall\n",
    "print(\"Recall-Score:\", recall_score(target_valid, predicted_valid_3))\n",
    "\n",
    "# Calculamos  F1\n",
    "print(\"F1-Score:\", f1_score(target_valid, predicted_valid_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "- Precision nos muestra que de todos los clientes que el modelo predijo que se ir√≠an, el 69.78% realmente se fueron.\n",
    "- Recall nos muestra que de todos los clientes que realmente se fueron, el modelo  detect√≥ el 47.47%.\n",
    "- El valor de F1 muestra un desempe√±o de 0.565. Aunque est√° muy cerca, todav√≠a le falta para alcanzar el umbral de 0.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Conclusiones sobre los modelos sin balancear ni escalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "- Los modelos de √Årbol de Decisi√≥n y Bosque Aleatorio mostraron un desempe√±o superior al modelo de Regresi√≥n Log√≠stica, tanto en precisi√≥n, recall y F1-Score, acerc√°ndose al umbral objetivo de 0.59 para F1.\n",
    "\n",
    "- El Bosque Aleatorio present√≥ una ligera mejora en la capacidad de detecci√≥n de clientes que efectivamente se fueron del banco, con un recall 0.93% mayor respecto al √Årbol de Decisi√≥n, aunque su F1-Score result√≥ levemente inferior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br>\n",
    "\n",
    "<b>√âxito</b> - ¬°Muy bien hecho! Has implementado correctamente tres modelos distintos (Regresi√≥n Log√≠stica, √Årbol de Decisi√≥n y Bosque Aleatorio), comparando sus m√©tricas clave sin aplicar t√©cnicas de balanceo. Especial menci√≥n al uso de ciclos para optimizaci√≥n de hiperpar√°metros (max_depth, n_estimators) y la claridad con la que interpretas precisi√≥n, recall y F1. Tus conclusiones reflejan una comprensi√≥n s√≥lida del comportamiento de modelos en datasets desbalanceados. ¬°Sigue as√≠!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Entrenamiento de modelos con clases equilibrados y carateristicas escaladas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Modelos de Regresion Logistica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Regresi√≥n Log√≠stica balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-Score: 0.37475149105367794\n",
      "Recall-Score: 0.7046728971962617\n",
      "F1-Score: 0.48929266709928615\n"
     ]
    }
   ],
   "source": [
    "# Definimos el modelo con LogisticRegression\n",
    "model_4 = LogisticRegression(random_state = 12345, solver = 'liblinear', class_weight = 'balanced')\n",
    "\n",
    "# Entrenamos al modelo con features_train y target_train\n",
    "model_4.fit(features_train, target_train)\n",
    "\n",
    "# Definimos una variable para las predicciones del modelo\n",
    "predicted_valid_4 = model_4.predict(features_valid)\n",
    "\n",
    "# Calculamos  Precision\n",
    "print(\"Precision-Score:\", precision_score(target_valid, predicted_valid_4))\n",
    "\n",
    "# Calculamos  Recall\n",
    "print(\"Recall-Score:\", recall_score(target_valid, predicted_valid_4))\n",
    "\n",
    "# Calculamos  F1\n",
    "print(\"F1-Score:\", f1_score(target_valid, predicted_valid_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones.**\n",
    "\n",
    "- Precision nos muestra que de todos los clientes que el modelo predijo que se ir√≠an, solo el 37.47% realmente se fueron.\n",
    "- Recall nos muestra que de todos los clientes que realmente se fueron, el modelo solo detect√≥ el 70.46%.\n",
    "- El valor de F1 muestra un desempe√±o de 0.489. Aun le falta para alcanzar el umbral de 0.59.\n",
    "\n",
    "**Comparacion con el modelo no balanceado:** \n",
    "- Vemos una disminucion en la precision.\n",
    "- Aumento en la detecci√≥n de clientes que se fueron.\n",
    "- Aumento en el desempe√±o general del modelo pero sin alcanzar el umbral objetivo de 0.59.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2.Regresi√≥n log√≠stica balanceada y escalado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5050234427327529\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos el scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustamos y transformamos solo las features de entrenamiento\n",
    "scaler.fit(features_train)\n",
    "features_train_esc = scaler.transform(features_train)\n",
    "features_valid_esc = scaler.transform(features_valid)\n",
    "\n",
    "# Creamos el modelo \n",
    "model_logreg = LogisticRegression(random_state=12345, solver='liblinear', class_weight = 'balanced')\n",
    "model_logreg.fit(features_train_esc, target_train)\n",
    "predicted_valid_logreg = model_logreg.predict(features_valid_esc)\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_valid_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "- El modelo presenta un desempe√±o inferior al requerido de 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Regresi√≥n Log√≠stica con Sobremuestreo, balaceada y escalado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5050234427327529\n"
     ]
    }
   ],
   "source": [
    "# Convertir numpy array escalado a DataFrame y resetear √≠ndices\n",
    "features_train_esc_df = pd.DataFrame(features_train_esc, columns=features_train.columns).reset_index(drop=True)\n",
    "target_train_reset = target_train.reset_index(drop=True)\n",
    "\n",
    "# Escribimos una funcion para el sobremuestreo.\n",
    "def upsample(features, target, repeat):\n",
    "\n",
    "    # Separamos las clases\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    # Mezclamos aleatoriamente los datos balanceados\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "\n",
    "# Creamos las variables llamando a la funcion upsample y usando las variables escaladas.\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train_esc_df, target_train_reset, 10\n",
    ")\n",
    "\n",
    "# Creamos y entrenamos el modelo de regresi√≥n log√≠stica\n",
    "model_5 = LogisticRegression(random_state = 12345, solver = 'liblinear', class_weight = 'balanced')\n",
    "model_5.fit(features_upsampled,target_upsampled)\n",
    "predicted_valid_5 = model_5.predict(features_valid_esc)\n",
    "\n",
    "# Mostramos el valor de F1\n",
    "print('F1:', f1_score(target_valid, predicted_valid_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "- El modelo presenta un desempe√±o inferior al requerido de 0.59 y un desemep√±o similar al modelo sin sobremuestreo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. Regresi√≥n Log√≠stica con Submuestreo, escalado y balanceada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5099601593625498\n"
     ]
    }
   ],
   "source": [
    "# Escribimos una funcion para el submuestreo.\n",
    "def downsample(features, target, fraction):\n",
    "    \n",
    "    # Separamos las clases\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [target_ones]\n",
    "    )\n",
    "    \n",
    "    # Mezclamos aleatoriamente los datos balanceados\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "# Creamos las variables llamando a la funcion downsample y usando las variables escaladas.\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    features_train_esc_df, target_train_reset, 0.1\n",
    ")\n",
    "\n",
    "# Creamos y entrenamos el modelo de regresi√≥n log√≠stica\n",
    "model_6 = LogisticRegression(random_state=12345, solver = 'liblinear', class_weight = 'balanced')\n",
    "model_6.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid_6 = model_6.predict(features_valid_esc)\n",
    "\n",
    "print('F1:', f1_score(target_valid, predicted_valid_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "- El modelo no alcanza el valor necesario de 0.59 para F1.\n",
    "- El modelo con submuestreo muestra un resultado ligeramente superior al modelo con sobremeustreo pero sin mejora significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Modelo de Arbol de Decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. √Årbol de Decisi√≥n balanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5290780141843971\n",
      "Recall: 0.697196261682243\n",
      "F1: 0.6016129032258064\n"
     ]
    }
   ],
   "source": [
    "# Definimos y entrenamos el modelo teniendo en cuenta los hiperparametros.\n",
    "model_7 = DecisionTreeClassifier(random_state=12345, max_depth=5, class_weight = 'balanced')\n",
    "model_7.fit(features_train, target_train)\n",
    "predicted_valid_7 = model_7.predict(features_valid)\n",
    "\n",
    "# Calculamos  Precision\n",
    "print('Precision:', precision_score(target_valid, predicted_valid_7))\n",
    "\n",
    "# Calculamos  Recall\n",
    "print('Recall:', recall_score(target_valid, predicted_valid_7))\n",
    "\n",
    "# Calculamos  F1\n",
    "print('F1:', f1_score(target_valid, predicted_valid_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "- El modelo con clase balanceada muestra un valor para F1 de 0.60 superando el valor necesario de 0.59 para F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. √Årbol de Decisi√≥n con Sobremuestreo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.3525535420098847\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo usando las variables resultantes de la funcion upsample\n",
    "model_8 = DecisionTreeClassifier(random_state=12345, max_depth=5)\n",
    "model_8.fit(features_upsampled,target_upsampled)\n",
    "predicted_valid_8 = model_8.predict(features_valid)\n",
    "\n",
    "# Mostramos el valor para F1\n",
    "print('F1:', f1_score(predicted_valid_8, target_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "- El modelo no alcanza el valor necesario de 0.59 para F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. √Årbol de Decisi√≥n con Submuestreo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.060390763765541734\n"
     ]
    }
   ],
   "source": [
    "# # Creamos el modelo usando las variables resultantes de la funcion downsample\n",
    "model_9 = DecisionTreeClassifier(random_state=12345, max_depth=5)\n",
    "model_9.fit(features_downsampled,target_downsampled)\n",
    "predicted_valid_9 = model_9.predict(features_valid)\n",
    "\n",
    "# Mostramos el valor para F1\n",
    "print('F1:', f1_score(predicted_valid_9, target_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "- El modelo no alcanza el valor necesario de 0.59 para F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4. Conclusiones sobre los modelos de Arbol de Decision con equilibrio de clases.\n",
    "\n",
    "- El Arbol de Decision Balanceado mostr√≥ el mejor desempe√±o para F1= 0.60.\n",
    "- El arbol de decision sobremuestrado mostr√≥ un desempe√±o inferior en F1 con un valor de 0.35\n",
    "- el arbol de decision submuestrado mostr√≥ el menor desempe√±o de los 3 modelos con un valor de F1=0.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Bosque Aleatorio Balanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-Score: 0.7205882352941176\n",
      "Recall-Score: 0.45794392523364486\n",
      "F1-Score: 0.5599999999999999\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo de Bosque Aleatorio teniendo en cuenta los hiperparametros.\n",
    "model_10 = RandomForestClassifier(random_state=54321, n_estimators=9, class_weight = 'balanced')\n",
    "model_10.fit(features_train, target_train)\n",
    "predicted_valid_10 = model_10.predict(features_valid)\n",
    "\n",
    "# Calculamos  Precision\n",
    "print(\"Precision-Score:\", precision_score(target_valid, predicted_valid_10))\n",
    "\n",
    "# Calculamos  Recall\n",
    "print(\"Recall-Score:\", recall_score(target_valid, predicted_valid_10))\n",
    "\n",
    "# Calculamos  F1\n",
    "print(\"F1-Score:\", f1_score(target_valid, predicted_valid_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "- El modelo muestra un desempe√±o cercano pero inferior al requerido de 0.59 para F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br>\n",
    "\n",
    "<b>√âxito</b> - Excelente avance en la secci√≥n de modelos con clases equilibradas y caracter√≠sticas escaladas. Has aplicado correctamente varias t√©cnicas de balanceo (ponderaci√≥n de clases, sobremuestreo, submuestreo) y evaluado su impacto en distintos algoritmos. Destaco especialmente el √Årbol de Decisi√≥n balanceado que supera el umbral de F1 ‚â• 0.59, cumpliendo as√≠ con los objetivos del proyecto. Tu an√°lisis comparativo demuestra un enfoque s√≥lido y reflexivo. ¬°Sigue as√≠!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Curva ROC para el modelo con mejor desempe√±o en F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente tabla presentamos el desempe√±o  medido por F1 para los modelos con clase balanceada y correcci√≥n de equilibrio.\n",
    "\n",
    "| Modelo | Valor F1|\n",
    "|---|---|\n",
    "| Regresi√≥n Log√≠stica balanceada|  0.489 | \n",
    "| Regresi√≥n Log√≠stica balanceada + Escalado | 0.505 | \n",
    "| Regresi√≥n Log√≠stica + Sobremuestreo + Escalado | 0.505 | \n",
    "| Regresi√≥n Log√≠stica + Submuestreo + Escalado | 0.5099 |\n",
    "| **√Årbol de Decisi√≥n balanceado** | **0.60** |\n",
    "| √Årbol de Decisi√≥n + Sobremuestreo | 0.352 |\n",
    "| √Årbol de Decisi√≥n + Submuestreo | 0.060 | \n",
    "| Bosque Aleatorio balanceado | 0.559 |\n",
    "\n",
    "- El Modelo de  **√Årbol de Decisi√≥n Balanceado** muestra el mejor desempe√±o de todos los modelos planteados.\n",
    "- El Modelo de  **√Årbol de Decisi√≥n Balanceado** supera el valor requerido de 0.59 para F1.\n",
    "\n",
    "Teniendo esto en cuenta, hallaremos el valor de AUC ROC para este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6016129032258064\n",
      "AUC-ROC: 0.8461211386173932\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo final con los hiperparametros que maximizaron su rendimiento.\n",
    "model_tree_final = DecisionTreeClassifier(random_state=12345, max_depth=5, class_weight = 'balanced')\n",
    "\n",
    "# Entrenamos el modelo \n",
    "model_tree_final.fit(features_train, target_train)\n",
    "predicted_valid_final = model_tree_final.predict(features_valid)\n",
    "\n",
    "# Calculamos  F1\n",
    "print('F1:', f1_score(target_valid, predicted_valid_final))\n",
    "\n",
    "# Predecimos las probabilidades para la clase positiva\n",
    "probs_valid = model_tree_final.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# Calculamos AUC-ROC\n",
    "auc_roc = roc_auc_score(target_valid, probs_valid)\n",
    "print('AUC-ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observacion:** \n",
    "- Muestra un AUC-ROC de 0.846, indicando que el modelo tiene una excelente capacidad para diferenciar entre las clases positivas y negativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras el an√°lisis comparativo, se determin√≥ que el modelo **√Årbol de Decisi√≥n con clases balanceadas alcanz√≥ el mejor desempe√±o, con un valor F1 de 0.60**, superando el umbral establecido de 0.59. Adem√°s, este modelo obtuvo un **valor de AUC-ROC de 0.846, evidenciando una adecuada capacidad para discriminar entre las clases positivas y negativas.**\n",
    "\n",
    "Los resultados mostraron que, si bien las t√©cnicas de sobremuestreo y submuestreo aportan mejoras en modelos como la Regresi√≥n Log√≠stica, su efecto en √Årboles de Decisi√≥n no siempre es favorable. En este caso particular, el ajuste mediante pesos de clase en el √Årbol de Decisi√≥n result√≥ ser la estrategia m√°s efectiva.\n",
    "\n",
    "Con base en estos hallazgos, se recomienda utilizar el √Årbol de Decisi√≥n balanceado como modelo final para este problema de clasificaci√≥n, por su solidez en t√©rminos de precisi√≥n, equilibrio en la clasificaci√≥n de ambas clases y su adecuada √°rea bajo la curva ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentario general del revisor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "¬°Felicidades, Cristian! Tu proyecto est√° <b>aprobado</b>. Has demostrado un s√≥lido conocimiento en el manejo de datos, desarrollo y evaluaci√≥n de modelos de clasificaci√≥n, aplicando t√©cnicas esenciales para tratar conjuntos desbalanceados. Tu an√°lisis paso a paso est√° muy bien documentado y el uso de m√©tricas relevantes permite entender claramente la toma de decisiones durante la optimizaci√≥n de los modelos.\n",
    "\n",
    "#### Puntos Positivos:\n",
    "\n",
    "* **Limpieza de datos:** Excelente manejo de valores nulos, justificado y correctamente ejecutado.\n",
    "* **Codificaci√≥n de variables categ√≥ricas:** Implementaci√≥n adecuada de one-hot encoding sin p√©rdida de informaci√≥n.\n",
    "* **Balanceo de clases:** Aplicaste diversas t√©cnicas (class\\_weight, upsampling, downsampling) y comparaste su impacto con criterio.\n",
    "* **Evaluaci√≥n de modelos:** Uso exhaustivo de F1, precisi√≥n, recall, y AUC-ROC con reflexiones claras sobre sus implicaciones.\n",
    "* **Selecci√≥n del mejor modelo:** Fundada en m√©tricas y resultados, seleccionando el √Årbol de Decisi√≥n balanceado como el m√°s eficaz.\n",
    "\n",
    "#### √Åreas para Seguir Investigando:\n",
    "\n",
    "* **Optimizaci√≥n de hiperpar√°metros:** Podr√≠as explorar `GridSearchCV` o `RandomizedSearchCV` para encontrar combinaciones m√°s robustas.\n",
    "* **Cross-validation estratificado:** Aporta mayor estabilidad al evaluar modelos, especialmente en datasets desbalanceados.\n",
    "* **Manejo avanzado de desbalance:** T√©cnicas como SMOTE o ADASYN podr√≠an potenciar a√∫n m√°s el rendimiento.\n",
    "* **Evaluaci√≥n econ√≥mica del modelo:** Analizar el impacto financiero de falsos positivos/negativos para el negocio.\n",
    "\n",
    "¬°Sigue as√≠, est√°s haciendo un gran trabajo! \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
